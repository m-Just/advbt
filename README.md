# advbt
Adversarial Backtracking (feat. cleverhans)
Neural  network  is  well-known  to  be  susceptible  to  adversarial  examples  withhuman-imperceptible perturbations.  There have been a lot of efforts put in de-veloping more robust models and detection of adversarial examples.   However,few advancement has been made in transformation-based methods. In this paper,we propose a novel defense mechanism which defends by performing adversarialattack on adversarial images. Without further complications in training, it restoresthe predictions with high confidence.   Through experiments,  we show that thismethod can restore the label of adversarial images, up to 98% on MNIST, upto 95% on CIFAR-10 .  As such, it can be applied to defend deployedmodels against malicious attacks.
